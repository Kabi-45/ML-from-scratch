{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTMm9fsuE3lezB/KW9EOXF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kabi-45/ML-from-scratch/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Linear Regression using Normal Equation\n",
        "import numpy as np\n",
        "class LinearRegressionOLS:\n",
        "    def __init__(self):\n",
        "        self.weights = None  # To store model coefficients (weights)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        # Add bias (intercept) term to the feature matrix\n",
        "        X_bias = np.c_[np.ones(X.shape[0]), X]  # Add a column of ones for the intercept\n",
        "\n",
        "        # Normal equation: beta = (X^T X)^-1 X^T y\n",
        "        X_transpose = X_bias.T\n",
        "        beta = np.linalg.inv(X_transpose @ X_bias) @ X_transpose @ y\n",
        "        self.weights = beta\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        # Add bias (intercept) term to the feature matrix\n",
        "        X_bias = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "        # Compute predictions: y = X_bias @ beta\n",
        "        return X_bias @ self.weights\n",
        "\n",
        "\n",
        "\n",
        "# Sample Dataset\n",
        "# Features (X) and target (y)\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegressionOLS()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "print(f\"Predictions: {y_pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agmXP9dpn_A3",
        "outputId": "d9972994-7e0a-419d-c89d-2b42bd8a1110"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [ 2.  4.  6.  8. 10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Linear Regression using Gradient Descent\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Ensure X is a 2D array\n",
        "        if len(X.shape) == 1:\n",
        "            X = X.reshape(-1, 1)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)  # Initialize weights\n",
        "        # (1/ n) X.T x (Xβ−y)\n",
        "        for _ in range(self.n_iterations):\n",
        "            predictions = X.dot(self.weights)  # Predicted values\n",
        "            errors = predictions - y          # Errors\n",
        "            gradient = (1 / n_samples) * X.T.dot(errors)  # Gradient\n",
        "            self.weights -= self.learning_rate * gradient  # Update weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        if len(X.shape) == 1:\n",
        "            X = X.reshape(-1, 1)\n",
        "        return X.dot(self.weights)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[1], [2], [3], [4], [5]])  # Shape: (5, 1)\n",
        "y = np.array([2, 4, 6, 8, 10])           # Shape: (5,)\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression(learning_rate=0.01, n_iterations=1000)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "print(f\"Predictions: {predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9I6GFWwl9O2",
        "outputId": "2284723d-7d08-4f89-a953-f30919c8ae6d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [ 2.  4.  6.  8. 10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RidgeRegression in Normal Equation (closed form)\n",
        "import numpy as np\n",
        "\n",
        "class RidgeRegression:\n",
        "  def __init__(self, alpha = 0.1):\n",
        "    self.alpha = alpha\n",
        "    self.weigths = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "\n",
        "    # Ensure X is a 2D array\n",
        "    if len(X.shape) == 1:\n",
        "      X = X.reshape(-1, 1)\n",
        "    n, m = X.shape\n",
        "    I = np.identity(m)\n",
        "    I[0][0] = 0\n",
        "    X_bias = np.c_[np.ones(n), X]\n",
        "    X_transpose = X_bias.T\n",
        "    self.weights = np.linalg.inv(X_transpose @ X_bias + self.alpha * I) @ X_transpose @ y\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "    return X_test @ self.weights\n",
        "\n",
        "\n",
        "# Sample Dataset\n",
        "# Features (X) and target (y)\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([1.2, 1.9, 3.0, 3.8, 5.1])\n",
        "\n",
        "# Initialize the model\n",
        "model = RidgeRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "print(f\"Predictions: {y_pred}\")\n"
      ],
      "metadata": {
        "id": "79Y62cjfxMpz",
        "outputId": "b9948631-50c0-48a7-a11e-3854ce9c5559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1.06 2.03 3.   3.97 4.94]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title RidgeLinearRegression using Gradient method\n",
        "\n",
        "import numpy as np\n",
        "class RidgeRegressionGD:\n",
        "\n",
        "  def __init__(self, max_iter = 1000, learning_rate = 0.01, alpha = 0.1, tolerance = 1e-6):\n",
        "    self.coef_ = None\n",
        "    self.intercept_ = None\n",
        "    self.max_iter = max_iter\n",
        "    self.learning_rate = learning_rate\n",
        "    self.alpha = alpha\n",
        "    self.tolerance = tolerance\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    X = np.c_[np.ones((X.shape[0],1)), X]\n",
        "    n_samples, n_features = X.shape\n",
        "    self.coef_ = np.zeros(n_features)\n",
        "    X_transpose = X.T\n",
        "    # (1/ n) X.T x (Xβ−y) + α/n * β\n",
        "    for i in range(self.max_iter):\n",
        "      y_pred = np.dot(X, self.coef_)\n",
        "      error = y - y_pred\n",
        "      gradient = -(1 / n_samples) * ( X_transpose @ error) + (self.alpha / n_samples) * self.coef_\n",
        "      gradient[0] -= (self.alpha / n_samples) * self.coef_[0]\n",
        "      self.coef_ -= self.learning_rate * gradient\n",
        "\n",
        "      cost = (1 / (2 * n_samples)) * np.sum(error ** 2) + (self.alpha / (2 * n_samples)) * np.sum(self.coef_[1:] ** 2)\n",
        "\n",
        "      # Check for convergence\n",
        "      if i > 0 and abs(prev_cost - cost) < self.tolerance:\n",
        "          print(f\"Converged after {i} iterations.\")\n",
        "          break\n",
        "      prev_cost = cost\n",
        "\n",
        "    self.intercept_ = self.coef_[0]\n",
        "    self.coef_ = self.coef_[1:]\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    X = np.c_[np.ones((X.shape[0],1)), X]\n",
        "    return X @ np.r_[self.intercept_, self.coef_]\n",
        "\n",
        "\n",
        "\n",
        "# Sample Dataset\n",
        "# Features (X) and target (y)\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([1.2, 1.9, 3.0, 3.8, 5.1])\n",
        "\n",
        "# Initialize the model\n",
        "model = RidgeRegressionGD()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "print(f\"Predictions: {y_pred}\")\n",
        "\n",
        "print(model.coef_)\n",
        "print(model.intercept_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pLMtLgyIEpEm",
        "outputId": "f362c3af-e3f6-44c5-bd30-2c7315449232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged after 517 iterations.\n",
            "Predictions: [1.11996269 2.06478273 3.00960276 3.95442279 4.89924282]\n",
            "[0.94482003]\n",
            "0.1751426607529812\n"
          ]
        }
      ]
    }
  ]
}